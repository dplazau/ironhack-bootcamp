{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I was facing some issues with the code so decided to try it out in colab\n",
    "# the following code is also needed for it to run\n",
    "\n",
    "# !pip install webdriver_manager selenium\n",
    "# !apt-get update\n",
    "# !apt install chromium-chromedriver\n",
    "# !cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
    "# import sys\n",
    "# sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import DictWriter\n",
    "from datetime import datetime\n",
    "from multiprocessing.connection import wait\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "# import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from helium import *\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n",
    "\n",
    "# splash container needed https://splash.readthedocs.io/en/stable/install.html\n",
    "def get_soup(url, driver):\n",
    "    # response = requests.get('http://localhost:8050/render.html', params={'url': url, 'wait': 5})\n",
    "    driver.get(url)\n",
    "    products = WebDriverWait(driver, 20).until(EC.visibility_of_all_elements_located((By.CLASS_NAME, \"product-row\")))\n",
    "    return products\n",
    "\n",
    "\n",
    "def get_product_attributes(products):\n",
    "    products_list = []\n",
    "    for product in products:\n",
    "        product_dict = {}\n",
    "        product = product.get_attribute(\"outerHTML\")\n",
    "        product_soup = BeautifulSoup(product, 'html.parser')\n",
    "        product_specs_list = product_soup.find('a').get_attribute_list(key=\"aria-label\")[0].split(\", \")\n",
    "        for spec in product_specs_list:\n",
    "            spec = spec.split(\": \")\n",
    "            if len(spec) > 1:\n",
    "                key = spec[0]\n",
    "                value = spec[1]\n",
    "                product_dict[key] = value        \n",
    "        products_list.append(product_dict)\n",
    "    return products_list\n",
    "    \n",
    "\n",
    "def main ():\n",
    "\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    driver = webdriver.Chrome('chromedriver', chrome_options=chrome_options)\n",
    "    # driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    url = 'https://products.embraco.com/compressors'\n",
    "    time_stamp = datetime.today().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    file_type = \".csv\"\n",
    "    file_name = f'COMPRESSORS-{time_stamp}{file_type}'\n",
    "    page_products = get_soup(url, driver)\n",
    "    next_btn = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.CLASS_NAME, \"next\")))\n",
    "    products_list = get_product_attributes(page_products)\n",
    "    keys = products_list[0].keys()\n",
    "    try:\n",
    "        counter = 1\n",
    "        with open (file_name, \"w\", encoding='utf-8' ) as csv_file:\n",
    "            csv_writer = DictWriter(csv_file, keys)\n",
    "            csv_writer.writeheader()            \n",
    "            while next_btn and not next_btn.get_property('disabled'):\n",
    "                next_btn = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.CLASS_NAME, \"next\")))\n",
    "                print(f\"Scraping page: {counter}\", not next_btn.get_property('disabled'))\n",
    "                csv_writer.writerows(products_list)\n",
    "                next_btn.click()        \n",
    "                products_list = get_product_attributes(page_products)\n",
    "                counter += 1\n",
    "    except PermissionError as err:\n",
    "        print(err, 'If you have the file open close it please!')\n",
    "    except KeyboardInterrupt as err:\n",
    "        print(err, 'The user has cancelled the scraping...')\n",
    "    except StaleElementReferenceException as err:\n",
    "      print(err, \"Don't know what this is...\")\n",
    "    except:\n",
    "        raise\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        csv_file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if '__main__' == __name__:\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d6993cb2f9ce9a59d5d7380609d9cb5192a9dedd2735a011418ad9e827eb538"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
